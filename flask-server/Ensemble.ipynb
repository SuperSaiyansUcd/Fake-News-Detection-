{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "701af167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maddy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maddy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maddy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "7a7c8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('Features_For_Traditional_ML_Techniques.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "e5d1c006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>majority_target</th>\n",
       "      <th>statement</th>\n",
       "      <th>BinaryNumTarget</th>\n",
       "      <th>tweet</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>...</th>\n",
       "      <th>determiners</th>\n",
       "      <th>conjunctions</th>\n",
       "      <th>dots</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>questions</th>\n",
       "      <th>ampersand</th>\n",
       "      <th>capitals</th>\n",
       "      <th>digits</th>\n",
       "      <th>long_word_freq</th>\n",
       "      <th>short_word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>End of eviction moratorium means millions of A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@POTUS Biden Blunders - 6 Month Update\\n\\nInfl...</td>\n",
       "      <td>4262.0</td>\n",
       "      <td>3619.0</td>\n",
       "      <td>34945.0</td>\n",
       "      <td>16423.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>End of eviction moratorium means millions of A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@S0SickRick @Stairmaster_ @6d6f636869 Not as m...</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>31436.0</td>\n",
       "      <td>37184.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>End of eviction moratorium means millions of A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>THE SUPREME COURT is siding with super rich pr...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  majority_target  \\\n",
       "0           0             True   \n",
       "1           1             True   \n",
       "2           2             True   \n",
       "\n",
       "                                           statement  BinaryNumTarget  \\\n",
       "0  End of eviction moratorium means millions of A...              1.0   \n",
       "1  End of eviction moratorium means millions of A...              1.0   \n",
       "2  End of eviction moratorium means millions of A...              1.0   \n",
       "\n",
       "                                               tweet  followers_count  \\\n",
       "0  @POTUS Biden Blunders - 6 Month Update\\n\\nInfl...           4262.0   \n",
       "1  @S0SickRick @Stairmaster_ @6d6f636869 Not as m...           1393.0   \n",
       "2  THE SUPREME COURT is siding with super rich pr...              9.0   \n",
       "\n",
       "   friends_count  favourites_count  statuses_count  listed_count  ...  \\\n",
       "0         3619.0           34945.0         16423.0          44.0  ...   \n",
       "1         1621.0           31436.0         37184.0          64.0  ...   \n",
       "2           84.0             219.0          1184.0           0.0  ...   \n",
       "\n",
       "   determiners conjunctions  dots  exclamation  questions  ampersand  \\\n",
       "0            0            0     5            0          1          0   \n",
       "1            0            2     1            0          0          0   \n",
       "2            0            1     0            0          0          0   \n",
       "\n",
       "   capitals  digits  long_word_freq  short_word_freq  \n",
       "0        33       3               5               19  \n",
       "1        14       0               2               34  \n",
       "2         3       0               4               10  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "277d89b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "3a16edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_scores'] = df['statement'].apply(lambda x: analyzer.polarity_scores(x))\n",
    "df['compound_sentiment'] = df['vader_scores'].apply(lambda x: 'positive' if x['compound'] >= 0.05 else 'negative' if x['compound'] <= -0.05 else 'neutral')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "6f2ae1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>majority_target</th>\n",
       "      <th>statement</th>\n",
       "      <th>BinaryNumTarget</th>\n",
       "      <th>tweet</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>...</th>\n",
       "      <th>dots</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>questions</th>\n",
       "      <th>ampersand</th>\n",
       "      <th>capitals</th>\n",
       "      <th>digits</th>\n",
       "      <th>long_word_freq</th>\n",
       "      <th>short_word_freq</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>compound_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>End of eviction moratorium means millions of A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@POTUS Biden Blunders - 6 Month Update\\n\\nInfl...</td>\n",
       "      <td>4262.0</td>\n",
       "      <td>3619.0</td>\n",
       "      <td>34945.0</td>\n",
       "      <td>16423.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>{'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>End of eviction moratorium means millions of A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@S0SickRick @Stairmaster_ @6d6f636869 Not as m...</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>31436.0</td>\n",
       "      <td>37184.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>{'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>End of eviction moratorium means millions of A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>THE SUPREME COURT is siding with super rich pr...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>End of eviction moratorium means millions of A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@POTUS Biden Blunders\\n\\nBroken campaign promi...</td>\n",
       "      <td>4262.0</td>\n",
       "      <td>3619.0</td>\n",
       "      <td>34945.0</td>\n",
       "      <td>16423.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>{'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  majority_target  \\\n",
       "0           0             True   \n",
       "1           1             True   \n",
       "2           2             True   \n",
       "3           3             True   \n",
       "\n",
       "                                           statement  BinaryNumTarget  \\\n",
       "0  End of eviction moratorium means millions of A...              1.0   \n",
       "1  End of eviction moratorium means millions of A...              1.0   \n",
       "2  End of eviction moratorium means millions of A...              1.0   \n",
       "3  End of eviction moratorium means millions of A...              1.0   \n",
       "\n",
       "                                               tweet  followers_count  \\\n",
       "0  @POTUS Biden Blunders - 6 Month Update\\n\\nInfl...           4262.0   \n",
       "1  @S0SickRick @Stairmaster_ @6d6f636869 Not as m...           1393.0   \n",
       "2  THE SUPREME COURT is siding with super rich pr...              9.0   \n",
       "3  @POTUS Biden Blunders\\n\\nBroken campaign promi...           4262.0   \n",
       "\n",
       "   friends_count  favourites_count  statuses_count  listed_count  ...  dots  \\\n",
       "0         3619.0           34945.0         16423.0          44.0  ...     5   \n",
       "1         1621.0           31436.0         37184.0          64.0  ...     1   \n",
       "2           84.0             219.0          1184.0           0.0  ...     0   \n",
       "3         3619.0           34945.0         16423.0          44.0  ...     3   \n",
       "\n",
       "  exclamation  questions  ampersand  capitals  digits  long_word_freq  \\\n",
       "0           0          1          0        33       3               5   \n",
       "1           0          0          0        14       0               2   \n",
       "2           0          0          0         3       0               4   \n",
       "3           0          0          1         6       8               1   \n",
       "\n",
       "   short_word_freq                                       vader_scores  \\\n",
       "0               19  {'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...   \n",
       "1               34  {'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...   \n",
       "2               10  {'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...   \n",
       "3               30  {'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...   \n",
       "\n",
       "   compound_sentiment  \n",
       "0            negative  \n",
       "1            negative  \n",
       "2            negative  \n",
       "3            negative  \n",
       "\n",
       "[4 rows x 66 columns]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "62a8b0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "df['preprocessed_text'] = df['statement'].apply(preprocess_text)\n",
    "df['text'] = df['preprocessed_text'] + df['tweet']\n",
    "df.drop(['statement', 'tweet'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "0f6755bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vadar_sentiment(text):\n",
    "    \"\"\" Calculate and return the nltk vadar (lexicon method) sentiment \"\"\"\n",
    "    return sent_i.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "c812a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_sentiment(sentiment, neg_threshold=-0.05, pos_threshold=0.05):\n",
    "    \"\"\" categorise the sentiment value as positive (1), negative (-1) \n",
    "        or neutral (0) based on given thresholds \"\"\"\n",
    "    if sentiment < neg_threshold:\n",
    "        label = 'negative'\n",
    "    elif sentiment > pos_threshold:\n",
    "        label = 'positive'\n",
    "    else:\n",
    "        label = 'neutral'\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "825be2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>majority_target</th>\n",
       "      <th>BinaryNumTarget</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>following</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>...</th>\n",
       "      <th>questions</th>\n",
       "      <th>ampersand</th>\n",
       "      <th>capitals</th>\n",
       "      <th>digits</th>\n",
       "      <th>long_word_freq</th>\n",
       "      <th>short_word_freq</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4262.0</td>\n",
       "      <td>3619.0</td>\n",
       "      <td>34945.0</td>\n",
       "      <td>16423.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>{'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>end eviction moratorium mean million american ...</td>\n",
       "      <td>end eviction moratorium mean million american ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  majority_target  BinaryNumTarget  followers_count  \\\n",
       "0           0             True              1.0           4262.0   \n",
       "\n",
       "   friends_count  favourites_count  statuses_count  listed_count  following  \\\n",
       "0         3619.0           34945.0         16423.0          44.0        0.0   \n",
       "\n",
       "                              embeddings  ...  questions  ampersand  capitals  \\\n",
       "0  [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]  ...          1          0        33   \n",
       "\n",
       "   digits  long_word_freq  short_word_freq  \\\n",
       "0       3               5               19   \n",
       "\n",
       "                                        vader_scores  compound_sentiment  \\\n",
       "0  {'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...            negative   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  end eviction moratorium mean million american ...   \n",
       "\n",
       "                                                text  \n",
       "0  end eviction moratorium mean million american ...  \n",
       "\n",
       "[1 rows x 66 columns]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "f7ba7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vadar compound'] = df['text'].apply(vadar_sentiment)\n",
    "df['vadar sentiment'] = df['vadar compound'].apply(categorise_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "a16adb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['preprocessed_text'].values\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "max_sequence_length = 100\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "89b034a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>majority_target</th>\n",
       "      <th>BinaryNumTarget</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>following</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>...</th>\n",
       "      <th>capitals</th>\n",
       "      <th>digits</th>\n",
       "      <th>long_word_freq</th>\n",
       "      <th>short_word_freq</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>text</th>\n",
       "      <th>vadar compound</th>\n",
       "      <th>vadar sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4262.0</td>\n",
       "      <td>3619.0</td>\n",
       "      <td>34945.0</td>\n",
       "      <td>16423.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>{'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>end eviction moratorium mean million american ...</td>\n",
       "      <td>end eviction moratorium mean million american ...</td>\n",
       "      <td>-0.9559</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  majority_target  BinaryNumTarget  followers_count  \\\n",
       "0           0             True              1.0           4262.0   \n",
       "\n",
       "   friends_count  favourites_count  statuses_count  listed_count  following  \\\n",
       "0         3619.0           34945.0         16423.0          44.0        0.0   \n",
       "\n",
       "                              embeddings  ...  capitals  digits  \\\n",
       "0  [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]  ...        33       3   \n",
       "\n",
       "   long_word_freq  short_word_freq  \\\n",
       "0               5               19   \n",
       "\n",
       "                                        vader_scores  compound_sentiment  \\\n",
       "0  {'neg': 0.275, 'neu': 0.725, 'pos': 0.0, 'comp...            negative   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  end eviction moratorium mean million american ...   \n",
       "\n",
       "                                                text  vadar compound  \\\n",
       "0  end eviction moratorium mean million american ...         -0.9559   \n",
       "\n",
       "   vadar sentiment  \n",
       "0         negative  \n",
       "\n",
       "[1 rows x 68 columns]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "5fd7d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "4475ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']  \n",
    "y = df['compound_sentiment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "278077c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label: index for index, label in enumerate(y.unique())}\n",
    "y = y.map(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "b437efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "2ca90a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000) \n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "a2d99e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive bayes\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "nb_pred = nb_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "118d9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#passive-aggressive\n",
    "pa_classifier = PassiveAggressiveClassifier(max_iter=100)\n",
    "pa_classifier.fit(X_train_tfidf, y_train)\n",
    "pa_pred = pa_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "ab5bb7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100 \n",
    "max_sequence_length = 1000 \n",
    "vocab_size = len(tfidf_vectorizer.vocabulary_)\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "22ee584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 1000, 100)         100000    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 100000)            0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 128)               12800128  \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,900,515\n",
      "Trainable params: 12,900,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length))\n",
    "deep_model.add(Flatten())\n",
    "deep_model.add(Dense(128, activation='relu'))\n",
    "deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "deep_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "deep_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "d9df0b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2684/2684 [==============================] - 321s 119ms/step - loss: 1.0785 - accuracy: 0.4238 - val_loss: 1.0701 - val_accuracy: 0.4255\n",
      "Epoch 2/10\n",
      "2684/2684 [==============================] - 311s 116ms/step - loss: 1.0705 - accuracy: 0.4290 - val_loss: 1.0701 - val_accuracy: 0.4255\n",
      "Epoch 3/10\n",
      "2684/2684 [==============================] - 314s 117ms/step - loss: 1.0715 - accuracy: 0.4289 - val_loss: 1.0697 - val_accuracy: 0.4255\n",
      "Epoch 4/10\n",
      "2684/2684 [==============================] - 315s 117ms/step - loss: 1.0695 - accuracy: 0.4290 - val_loss: 1.0696 - val_accuracy: 0.4255\n",
      "Epoch 5/10\n",
      "2684/2684 [==============================] - 313s 116ms/step - loss: 1.0695 - accuracy: 0.4290 - val_loss: 1.0695 - val_accuracy: 0.4255\n",
      "Epoch 6/10\n",
      "2684/2684 [==============================] - 316s 118ms/step - loss: 1.0695 - accuracy: 0.4290 - val_loss: 1.0695 - val_accuracy: 0.4255\n",
      "Epoch 7/10\n",
      "2684/2684 [==============================] - 314s 117ms/step - loss: 1.0695 - accuracy: 0.4290 - val_loss: 1.0694 - val_accuracy: 0.4255\n",
      "Epoch 8/10\n",
      "2684/2684 [==============================] - 312s 116ms/step - loss: 1.0695 - accuracy: 0.4290 - val_loss: 1.0695 - val_accuracy: 0.4255\n",
      "Epoch 9/10\n",
      "2684/2684 [==============================] - 316s 118ms/step - loss: 1.0695 - accuracy: 0.4290 - val_loss: 1.0696 - val_accuracy: 0.4255\n",
      "Epoch 10/10\n",
      "2684/2684 [==============================] - 317s 118ms/step - loss: 1.0695 - accuracy: 0.4290 - val_loss: 1.0695 - val_accuracy: 0.4255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16ced70d010>"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train_tfidf.toarray(), y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "c24538cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839/839 [==============================] - 7s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "nb_probabilities = nb_classifier.predict_proba(X_test_tfidf)\n",
    "pa_probabilities = pa_classifier.decision_function(X_test_tfidf)\n",
    "deep_probabilities = deep_model.predict(X_test_tfidf.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "b2b75745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.9518256333830104\n",
      "Ensemble Model Confusion Matrix:\n",
      " [[ 8736   319    85]\n",
      " [  275 10967   165]\n",
      " [  156   293  5844]]\n",
      "Ensemble Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      9140\n",
      "           1       0.95      0.96      0.95     11407\n",
      "           2       0.96      0.93      0.94      6293\n",
      "\n",
      "    accuracy                           0.95     26840\n",
      "   macro avg       0.95      0.95      0.95     26840\n",
      "weighted avg       0.95      0.95      0.95     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_probabilities = (nb_probabilities + pa_probabilities + deep_probabilities) / 3.0\n",
    "final_pred = np.argmax(combined_probabilities, axis=1)\n",
    "\n",
    "print(\"Ensemble Model Accuracy:\", accuracy_score(y_test, final_pred))\n",
    "print(\"Ensemble Model Confusion Matrix:\\n\", confusion_matrix(y_test, final_pred))\n",
    "print(\"Ensemble Model Classification Report:\\n\", classification_report(y_test, final_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "df669dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ensemble_model.pkl']"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model = {\n",
    "    'tfidf_vectorizer': tfidf_vectorizer,\n",
    "    'naivebayes_classifier': nb_classifier,\n",
    "    'passiveaggressive_classifier': pa_classifier,\n",
    "    'deep_model': deep_model\n",
    "}\n",
    "joblib.dump(ensemble_model, 'ensemble_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
