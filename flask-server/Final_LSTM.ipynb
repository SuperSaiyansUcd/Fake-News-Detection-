{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065b76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import re \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "plt.style.use('ggplot')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Embedding, LSTM, Bidirectional, Dropout, Concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e7f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeafbb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"truthseeker_sentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ed87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['BinaryNumTarget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fec53ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.0\n",
       "1         1.0\n",
       "2         1.0\n",
       "3         1.0\n",
       "4         1.0\n",
       "         ... \n",
       "134178    0.0\n",
       "134179    0.0\n",
       "134180    0.0\n",
       "134181    0.0\n",
       "134182    0.0\n",
       "Name: BinaryNumTarget, Length: 134183, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop('BinaryNumTarget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d73b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text', 'anger', 'disgust', 'fear', 'joy', 'neutral',\n",
    "       'sadness', 'surprise', 'positive_word_count', 'negative_word_count',\n",
    "       'vader_scores', 'textblob_scores', 'flair_scores', 'affin_score',\n",
    "       'pattern_score']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529559f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\natas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3754f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text column\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Join the tokens back into a single string\n",
    "    cleaned_text = ' '.join(filtered_tokens)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e15e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the clean_text function to the 'text' column\n",
    "X['text'] = X['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52019586",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e481ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e307e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sequences = tokenizer.texts_to_sequences(X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8045452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(len(sequence) for sequence in X_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c87093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded = tf.keras.preprocessing.sequence.pad_sequences(X_sequences, maxlen = max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90723ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_additional = X[['anger', 'disgust', 'fear', 'joy', 'neutral',\n",
    "       'sadness', 'surprise', 'positive_word_count', 'negative_word_count',\n",
    "       'vader_scores', 'textblob_scores', 'flair_scores', 'affin_score',\n",
    "       'pattern_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15f9c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert additional columns to numpy array\n",
    "X_additional = np.array(X_additional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d504d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text data and additional columns\n",
    "X_combined = np.concatenate((X_padded, X_additional), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6e0e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=1/4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea2343b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "#The model architecture is defined using the functional API of Keras, allowing for multiple input layers.\n",
    "#Two input layers are defined: input_text for the tokenized and padded text data, and \n",
    "#input_additional for the additional columns.\n",
    "    \n",
    "input_text = Input(shape=(max_sequence_length,))\n",
    "input_additional = Input(shape=(X_additional.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d914295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Embedding layer and Bi-LSTM layer\n",
    "embedding = Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_sequence_length)(input_text)\n",
    "lstm = Bidirectional(LSTM(64, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)))(embedding)\n",
    "\n",
    "# Concatenate LSTM output with the additional columns input\n",
    "concatenated = Concatenate()([lstm, input_additional])\n",
    "\n",
    "# Apply Dropout layer to the concatenated output\n",
    "dropout = Dropout(0.5)(concatenated)\n",
    "\n",
    "# Create the output layer with sigmoid activation for binary classification\n",
    "output = Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "# Create the model with both input layers and the output layer\n",
    "model = Model(inputs=[input_text, input_additional], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72232c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f679296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1573/1573 [==============================] - 333s 210ms/step - loss: 0.2176 - accuracy: 0.9697 - val_loss: 0.0413 - val_accuracy: 0.9972\n",
      "Epoch 2/10\n",
      "1573/1573 [==============================] - 338s 215ms/step - loss: 0.0253 - accuracy: 0.9989 - val_loss: 0.0216 - val_accuracy: 0.9984\n",
      "Epoch 3/10\n",
      "1573/1573 [==============================] - 329s 209ms/step - loss: 0.0246 - accuracy: 0.9975 - val_loss: 0.0351 - val_accuracy: 0.9948\n",
      "Epoch 4/10\n",
      "1573/1573 [==============================] - 334s 212ms/step - loss: 0.0123 - accuracy: 0.9993 - val_loss: 0.0152 - val_accuracy: 0.9979\n",
      "Epoch 5/10\n",
      "1573/1573 [==============================] - 340s 216ms/step - loss: 0.0071 - accuracy: 0.9998 - val_loss: 0.0129 - val_accuracy: 0.9984\n",
      "Epoch 6/10\n",
      " 974/1573 [=================>............] - ETA: 2:01 - loss: 0.0090 - accuracy: 0.9991"
     ]
    }
   ],
   "source": [
    "# Train the model with early stopping\n",
    "model.fit([X_train[:, :max_sequence_length], X_train[:, max_sequence_length:]], y_train,\n",
    "          validation_data=([X_test[:, :max_sequence_length], X_test[:, max_sequence_length:]], y_test),\n",
    "          epochs=10, batch_size=64, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac3e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X_test[:, :max_sequence_length], X_test[:, max_sequence_length:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0736af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01657b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6543208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(y_test, y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5542001",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "from afinn import Afinn\n",
    "from pattern.en import sentiment\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from pattern.en import sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c243d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment_features_text(text):\n",
    "\n",
    "    # Initialize the VADER SentimentIntensityAnalyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    flair_classifier = TextClassifier.load('en-sentiment')\n",
    "    \n",
    "    afinn = Afinn()\n",
    "\n",
    "    # Calculate positive and negative word counts, and sentiment score for the text\n",
    "    positive_count = len([word for word in text.split() if sid.polarity_scores(word)['compound'] > 0])\n",
    "    negative_count = len([word for word in text.split() if sid.polarity_scores(word)['compound'] < 0])\n",
    "    \n",
    "    #using vader and textblob\n",
    "    sentiment_score_vader = sid.polarity_scores(text)['compound']\n",
    "    sentiment_score_textblob = TextBlob(text).sentiment.polarity\n",
    "    \n",
    "    # Flair method\n",
    "    flair_sentence = Sentence(text)\n",
    "    flair_classifier.predict(flair_sentence)\n",
    "    flair_score = flair_sentence.labels[0].score\n",
    "    \n",
    "    # Afinn\n",
    "    affin_score = afinn.score(text)\n",
    "    \n",
    "    # Pattern\n",
    "    pattern_score = sentiment(text)[0]\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    data = {\n",
    "        'anger': [1 if emotion == \"anger\" else 0],\n",
    "        'disgust': [1 if emotion == \"disgust\" else 0],\n",
    "        'fear': [1 if emotion == \"fear\" else 0],\n",
    "        'joy': [1 if emotion == \"joy\" else 0],\n",
    "        'neutral': [1 if emotion == \"neutral\" else 0],\n",
    "        'sadness': [1 if emotion == \"sadness\" else 0],\n",
    "        'surprise': [1 if emotion == \"surprise\" else 0],\n",
    "        'positive_word_count': [positive_count],\n",
    "        'negative_word_count': [negative_count],\n",
    "        'vader_scores': [sentiment_score_vader],\n",
    "        'textblob_scores': [sentiment_score_textblob],\n",
    "        'flair_scores': [flair_score],\n",
    "        'affin_score': [affin_score],\n",
    "        'pattern_score': [pattern_score],\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_emotions_text(text, batch_size=8):\n",
    "    predicted_emotions = []\n",
    "    for i in range(0, len(text), batch_size):\n",
    "        batch_statements = text[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_statements, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
    "        label_to_emotion = {0: \"anger\", 1: \"disgust\", 2: \"fear\", 3: \"joy\", 4: \"neutral\", 5: \"sadness\", 6: \"surprise\"}\n",
    "        batch_emotions = [label_to_emotion[label.item()] for label in predicted_labels]\n",
    "        predicted_emotions.extend(batch_emotions)\n",
    "\n",
    "    return predicted_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"j-hartmann/emotion-english-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcef35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = \"NEW YORK (Reuters) - A federal appeals court in Virginia on Thursday rejected a bid by President Donald Trumpâ€™s administration to prevent the U.S. military from accepting transgender recruits starting Jan. 1. The administration had urged the appeals court to suspend an order by a federal judge in Baltimore for the armed forces to begin accepting transgender recruits on that date. The administration has said the Jan. 1 start date was causing the armed forces to scramble to revise their policies at the risk of harming military readiness.  In a brief two-paragraph order, the three-judge panel of the Richmond-based 4th U.S. Circuit Court of Appeals said it was denying the administrationâ€™s request while the appeal proceeds. All three judges are Democratic appointees.  The courtâ€™s action could prompt the administration to ask the conservative-majority U.S. Supreme Court to intervene. â€œWe disagree with the courtâ€™s ruling and are currently evaluating the next steps,â€ U.S. Justice Department spokeswoman Lauren Ehrsam said in a statement. Several transgender service members, backed by the American Civil Liberties Union, filed suit in Maryland after Trump said in July he would ban transgender people from the military, a move that would reverse a policy of the Republican presidentâ€™s Democratic predecessor Barack Obama to accept them. Trump cited concern over military focus and medical costs. So far, three federal judges around the country have issued injunctions blocking Trumpâ€™s ban. His administration has appealed all three rulings.  Joshua Block, an ACLU attorney who represents the plaintiffs in the Maryland case, said he was happy the appeals court saw through the governmentâ€™s â€œsmokescreenâ€ to further delay enlistment.  Thursdayâ€™s action was in response to the administrationâ€™s appeal of a Nov. 21 ruling by U.S. District Judge Marvin Garbis, who said that the transgender prohibition likely violates the plaintiffsâ€™ constitutional right to equal protection under the law. The Garbis ruling followed a similar one on Oct. 30 by another federal judge in Washington, D.C. A third judge in Seattle also ruled against the administration on Dec. 11. In an August memorandum, Trump gave the military until March 2018 to revert to a policy prohibiting openly transgender people from joining the military and authorizing their discharge. The memo also halted the use of government funds for sex-reassignment surgery for active-duty military personnel. The Obama administration had set a deadline of July 1 of this year to begin accepting transgender recruits. But Trumpâ€™s defense secretary, James Mattis, postponed that date to Jan. 1, which the presidentâ€™s ban then put off indefinitely. The Trump administration said in legal papers that the armed forces are not prepared to train thousands of personnel on the medical standards needed to process transgender applicants and might have to accept â€œsome individuals who are not medically fit for service.â€ The Pentagon on Dec. 8 issued guidelines to recruitment personnel in order to enlist transgender applicants by Jan. 1. The memo outlined medical requirements and specified how the applicantsâ€™ sex would be identified and even which undergarments they would wear. The banâ€™s challengers said the memo contradicted the claim that the military was not ready.  The Justice Department disagreed, telling the court on Wednesday that â€œall this memorandum shows is that the military is scrambling to comply with the injunction.â€ The lawsuitâ€™s lead plaintiff Brock Stone, 34, has served in the U.S. Navy for 11 years, including a nine-month deployment to Afghanistan, and wants to remain for at least 20 years, according to court papers.  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text_column': [text_input]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba9e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_emotions = classify_emotions(df['text_column'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, calculate_features_with_sentiment(df['text_column'].iloc[0])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87720c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a015bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1aab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model = pickle.load(open('model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aafcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
