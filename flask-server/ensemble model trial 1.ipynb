{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63106a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdc1b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"truthseeker_sentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3148daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert Categorical Variables\n",
    "# Assuming 'text' contains textual data, we'll use CountVectorizer or TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)  # You can also use CountVectorizer() instead\n",
    "X_text_features = vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "268afc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the text features with other numerical features using hstack (sparse matrix concatenation)\n",
    "numerical_features = df.drop(['BinaryNumTarget', 'text'], axis=1)\n",
    "X_numerical = numerical_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9b6965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = hstack([X_numerical, X_text_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0aeba3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Scale Numerical Features with `with_mean=False`\n",
    "scaler = StandardScaler(with_mean=False)  # Avoid centering for sparse data\n",
    "X_scaled = scaler.fit_transform(X_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d03016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df['BinaryNumTarget'], test_size=1/4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0940d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train individual classifiers\n",
    "#nb_classifier = GaussianNB()\n",
    "pa_classifier = PassiveAggressiveClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b9fc5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = SGDClassifier(loss='log', alpha=0.0001, max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f55eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000  # You can adjust this based on your memory availability\n",
    "n_samples = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e4a718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, n_samples, batch_size):\n",
    "    X_batch = X_train[i:i + batch_size].toarray()\n",
    "    y_batch = y_train[i:i + batch_size]\n",
    "    nb_classifier.partial_fit(X_batch, y_batch, classes=np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09ce2350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "637caee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Build the Neural Network model\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "nn_model.add(Dense(64, activation='relu'))\n",
    "nn_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d405e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc92dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Train the Neural Network in batches\n",
    "batch_size_nn = 32  # Adjust this based on your memory availability\n",
    "n_samples_nn = X_train.shape[0]\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7287f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, n_samples_nn, batch_size_nn):\n",
    "        X_batch_nn = X_train[i:i + batch_size_nn].toarray()  # Convert to dense array\n",
    "        y_batch_nn = y_train[i:i + batch_size_nn]\n",
    "        nn_model.train_on_batch(X_batch_nn, y_batch_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d1d4330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nTypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 511, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 511, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 507, in slice_array\n    return training_utils.slice_arrays(\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in slice_arrays\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_33907]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19016\\1702597901.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nTypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 511, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 511, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 507, in slice_array\n    return training_utils.slice_arrays(\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in slice_arrays\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\natas\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_33907]"
     ]
    }
   ],
   "source": [
    "#nn_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cbe5aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3145/3145 [==============================] - 3s 857us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Combine the predictions\n",
    "nb_predictions = nb_classifier.predict_proba(X_train)[:, 1]\n",
    "pa_predictions = pa_classifier.decision_function(X_train)\n",
    "nn_predictions = nn_model.predict(X_train).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd90fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new training set with the predictions of the individual classifiers\n",
    "ensemble_train = pd.DataFrame({\n",
    "    'NaiveBayes': nb_predictions,\n",
    "    'PassiveAggressive': pa_predictions,\n",
    "    'NeuralNetwork': nn_predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "49050991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Build an ensemble model\n",
    "ensemble_model = LogisticRegression()\n",
    "ensemble_model.fit(ensemble_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7bcd681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 1s 813us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the ensemble\n",
    "nb_test_predictions = nb_classifier.predict_proba(X_test)[:, 1]\n",
    "pa_test_predictions = pa_classifier.decision_function(X_test)\n",
    "nn_test_predictions = nn_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "44984470",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test = pd.DataFrame({\n",
    "    'NaiveBayes': nb_test_predictions,\n",
    "    'PassiveAggressive': pa_test_predictions,\n",
    "    'NeuralNetwork': nn_test_predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af04f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9939486078817147\n"
     ]
    }
   ],
   "source": [
    "ensemble_test_predictions = ensemble_model.predict(ensemble_test)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_test_predictions)\n",
    "print(\"Ensemble Accuracy:\", ensemble_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790c0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
